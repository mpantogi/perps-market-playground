"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.addOutputsToContext = exports.getOutputs = exports.getArtifacts = exports.runStep = exports.buildLayer = exports.build = exports.createInitialContext = void 0;
const debug_1 = __importDefault(require("debug"));
/* eslint-disable @typescript-eslint/no-non-null-assertion */
const lodash_1 = __importDefault(require("lodash"));
const viem = __importStar(require("viem"));
const actions_1 = require("./actions");
const constants_1 = require("./constants");
const runtime_1 = require("./runtime");
const util_1 = require("./util");
const debug = (0, debug_1.default)('cannon:builder');
const debugVerbose = (0, debug_1.default)('cannon:verbose:builder');
// a step is considered failed if it takes longer than 5 minutes always
const DEFAULT_STEP_TIMEOUT = 300000;
async function createInitialContext(def, pkg, chainId, opts) {
    const preCtx = {
        package: pkg,
        timestamp: Math.floor(Date.now() / 1000).toString(),
        chainId,
        overrideSettings: opts,
    };
    return {
        ...preCtx,
        contracts: {},
        txns: {},
        imports: {},
        settings: lodash_1.default.clone(opts),
    };
}
exports.createInitialContext = createInitialContext;
async function build(runtime, def, state, initialCtx) {
    debug('preflight');
    const problems = def.checkAll();
    if (problems) {
        throw new Error(`Your cannonfile is invalid: please resolve the following issues before building your project:
${(0, util_1.printChainDefinitionProblems)(problems)}`);
    }
    debug('build', initialCtx.settings);
    // sanity check the network
    await runtime.checkNetwork();
    initialCtx.chainId = runtime.chainId;
    state = lodash_1.default.cloneDeep(state);
    const tainted = new Set();
    const built = new Map();
    const topologicalActions = def.topologicalActions;
    let ctx;
    const name = def.getName(initialCtx);
    const version = def.getVersion(initialCtx);
    // whether or not source code is included in deployment artifacts or not is controlled by cannonfile config, so we set it here
    runtime.setPublicSourceCode(def.isPublicSourceCode());
    try {
        if (runtime.snapshots) {
            debug('building by layer');
            ctx = lodash_1.default.clone(initialCtx);
            for (const leaf of def.leaves) {
                await buildLayer(runtime, def, ctx, state, leaf, tainted, built);
            }
        }
        else {
            debug('building individual');
            doActions: for (const n of topologicalActions) {
                debug(`check action ${n}`);
                if (runtime.isCancelled()) {
                    debug('runtime cancelled');
                    break;
                }
                ctx = lodash_1.default.cloneDeep(initialCtx);
                const artifacts = {};
                let depsTainted = false;
                for (const dep of def.getDependencies(n)) {
                    if (!built.has(dep)) {
                        debug(`skip ${n} because previous operation incomplete`);
                        runtime.emit(runtime_1.Events.SkipDeploy, n, new Error(`dependency operation not completed: ${dep}`), 0);
                        continue doActions;
                    }
                    lodash_1.default.merge(artifacts, built.get(dep));
                    depsTainted = depsTainted || tainted.has(dep);
                }
                addOutputsToContext(ctx, artifacts);
                if (state[n]) {
                    if (state[n].version > constants_1.BUILD_VERSION) {
                        throw new Error('incompatible (newer) build version. please update cannon.');
                    }
                    // also add self artifacts here so that we can self-reference from inside the step
                    debug('adding self artifacts to context', state[n].artifacts);
                    addOutputsToContext(ctx, state[n].artifacts);
                }
                try {
                    const curHashes = await def.getState(n, runtime, ctx, depsTainted);
                    debug('comparing states', state[n] ? state[n].hash : null, curHashes);
                    if (!state[n] || (state[n].hash !== 'SKIP' && curHashes && !curHashes.includes(state[n].hash || ''))) {
                        debug('run isolated', n);
                        const newArtifacts = await runStep(runtime, { name, version, currentLabel: n }, def.getConfig(n, ctx), ctx);
                        // some steps may be self introspective, causing a step to be giving the wrong hash initially. to counteract this, we recompute the hash
                        addOutputsToContext(ctx, newArtifacts);
                        const newStates = await def.getState(n, runtime, ctx, depsTainted);
                        state[n] = {
                            artifacts: newArtifacts,
                            hash: newStates && newStates.length ? newStates[0] : null,
                            version: constants_1.BUILD_VERSION,
                        };
                        tainted.add(n);
                    }
                    else {
                        debug('skip isolated', n);
                    }
                    built.set(n, lodash_1.default.merge(artifacts, state[n].artifacts));
                }
                catch (err) {
                    debug('got error', err);
                    if (runtime.allowPartialDeploy) {
                        runtime.emit(runtime_1.Events.SkipDeploy, n, err, 0);
                        continue; // will skip saving the build artifacts, which should block any future jobs from finishing
                    }
                    else {
                        // make sure its possible to debug the original error
                        debug('error', err);
                        debugVerbose('context', JSON.stringify(ctx, null, 2));
                        throw err;
                    }
                }
            }
        }
    }
    catch (err) {
        // make sure its possible to debug the original error
        debug('error', err);
        debugVerbose('context', JSON.stringify(ctx, null, 2));
        throw err;
    }
    return state;
}
exports.build = build;
async function buildLayer(runtime, def, baseCtx, state, cur, tainted = new Set(), built = new Map()) {
    const layers = def.getStateLayers();
    const layer = layers[cur];
    // if layer is already done
    if (built.has(cur)) {
        return;
    }
    debug('eval build layer name', cur);
    const name = def.getName(baseCtx);
    const version = def.getVersion(baseCtx);
    // check all dependencies. If the dependency is not done, run the dep layer first
    let isCompleteLayer = true;
    for (const dep of layer.depends) {
        // this doesn't catch all cases of cycles but as a sanity check it works surprisingly well
        if (dep === cur) {
            throw new Error(`layer depends on itself: ${cur}`);
        }
        await buildLayer(runtime, def, baseCtx, state, dep, tainted, built);
        // if a prior layer had to be rebuilt, we must rebuild the current layer as well
        isCompleteLayer = isCompleteLayer && !tainted.has(dep);
    }
    // do all state layers match? if so, load the layer from cache and continue
    for (const action of layer.actions) {
        const ctx = lodash_1.default.cloneDeep(baseCtx);
        const depArtifacts = {};
        for (const dep of def.getDependencies(action)) {
            lodash_1.default.merge(depArtifacts, built.get(dep));
        }
        addOutputsToContext(ctx, depArtifacts);
        if (state[action] && state[action].artifacts) {
            if (state[action].version > constants_1.BUILD_VERSION) {
                throw new Error('incompatible (newer) build version. please update cannon.');
            }
            // also add self artifacts here so that we can self-reference from inside the step
            addOutputsToContext(ctx, state[action].artifacts);
        }
        try {
            const curHashes = await def.getState(action, runtime, ctx, false);
            if (isCompleteLayer) {
                debug('comparing layer states', state[action] ? state[action].hash : null, curHashes);
                if (!state[action] || (curHashes && !curHashes.includes(state[action].hash || ''))) {
                    debug('operation', action, 'in layer needs to be rebuilt');
                    isCompleteLayer = false;
                    break;
                }
                // in case we do not need to rebuild this layer we still need to set the built entry
                built.set(action, lodash_1.default.merge(depArtifacts, state[action].artifacts));
            }
        }
        catch (err) {
            // make sure its possible to debug the original error
            debug('error', err);
            // now log a more friendly message
            throw new Error(`Failure on operation ${action}: ${err.toString()}`);
        }
    }
    // if we get here, need to run a rebuild of layer
    if (!isCompleteLayer) {
        debug('run to complete layer', layer.actions, layer.depends);
        await runtime.clearNode();
        for (const dep of layer.depends) {
            if (state[dep].chainDump) {
                // chain dump may not exist if the package is a little older
                await runtime.loadState(state[dep].chainDump);
            }
            else {
                debug('warning: chain dump not recorded for layer:', dep);
            }
        }
        for (const action of layer.actions) {
            const ctx = lodash_1.default.cloneDeep(baseCtx);
            const depArtifacts = {};
            for (const dep of def.getDependencies(action)) {
                lodash_1.default.merge(depArtifacts, built.get(dep));
            }
            addOutputsToContext(ctx, depArtifacts);
            // also add self artifacts here so that we can self-reference from inside the step
            if (state[action] && state[action].artifacts) {
                debug('adding self artifacts to context', state[action].artifacts);
                addOutputsToContext(ctx, state[action].artifacts);
            }
            debug('run action in layer', action);
            const newArtifacts = await runStep(runtime, {
                name,
                version,
                currentLabel: action,
            }, def.getConfig(action, ctx), lodash_1.default.clone(ctx));
            addOutputsToContext(ctx, newArtifacts);
            const newHashes = await def.getState(action, runtime, ctx, false);
            state[action] = {
                artifacts: newArtifacts,
                hash: newHashes && newHashes.length ? newHashes[0] : null,
                version: constants_1.BUILD_VERSION,
                // add the chain dump later once all steps have been executed
            };
            tainted.add(action);
            built.set(action, lodash_1.default.merge(depArtifacts, state[action].artifacts));
        }
        // after all contexts are built, save all of them at the same time
        const chainDump = await runtime.dumpState();
        for (const action of layer.actions) {
            state[action].chainDump = chainDump;
        }
    }
}
exports.buildLayer = buildLayer;
async function runStep(runtime, pkgState, cfg, ctx) {
    const [type, label] = pkgState.currentLabel.split('.');
    runtime.emit(runtime_1.Events.PreStepExecute, type, label, cfg, 0);
    debugVerbose('ctx for operation', pkgState.currentLabel, ctx);
    // if there is an error then this will ensure the stack trace is printed with the latest
    runtime.updateProviderArtifacts(ctx);
    const result = await viem.withTimeout(() => {
        return actions_1.ActionKinds[type].exec(runtime, ctx, cfg, pkgState);
    }, {
        timeout: actions_1.ActionKinds[type].timeout || DEFAULT_STEP_TIMEOUT,
        errorInstance: new Error('timed out without error'),
    });
    runtime.emit(runtime_1.Events.PostStepExecute, type, label, cfg, ctx, result, 0);
    return result;
}
exports.runStep = runStep;
function getArtifacts(def, state) {
    const artifacts = {};
    for (const step of def.topologicalActions) {
        if (state[step] && state[step].artifacts) {
            lodash_1.default.merge(artifacts, state[step].artifacts);
        }
    }
    return artifacts;
}
exports.getArtifacts = getArtifacts;
async function getOutputs(runtime, def, state) {
    const artifacts = getArtifacts(def, state);
    if (runtime.snapshots) {
        // need to load state as well. the states that we want to load are the "leaf" layers
        const layers = lodash_1.default.uniq(Object.values(def.getStateLayers()));
        layerSearch: for (const layer of layers) {
            for (const action of layer.actions) {
                if (layers.find((l) => l.depends.indexOf(action) !== -1)) {
                    // this isnt a leaf
                    continue layerSearch;
                }
            }
            if (state[layer.actions[0]]?.chainDump) {
                await runtime.loadState(state[layer.actions[0]].chainDump);
            }
            else {
                debug(`warning: state dump not recorded for ${layer.actions[0]}`);
            }
        }
    }
    return artifacts;
}
exports.getOutputs = getOutputs;
// TODO: this func is dumb but I need to walk through this time period before I want to turn it into something of beauty
function addOutputsToContext(ctx, outputs) {
    const imports = outputs.imports;
    for (const imp in imports) {
        ctx.imports[imp] = imports[imp];
    }
    //helper function for recursively adding simplified imports notation
    function addSimplifiedAccessSyntax(ctx) {
        const simplifiedAccessObject = {};
        for (const contractName in ctx.contracts) {
            //also add simplified address syntax
            simplifiedAccessObject[contractName] = ctx.contracts[contractName];
        }
        for (const importName in ctx.imports) {
            simplifiedAccessObject[importName] = addSimplifiedAccessSyntax(ctx.imports[importName]);
        }
        return simplifiedAccessObject;
    }
    const contracts = outputs.contracts;
    for (const contractName in contracts) {
        ctx.contracts[contractName] = contracts[contractName];
    }
    const txns = outputs.txns;
    for (const txn in txns) {
        ctx.txns[txn] = txns[txn];
    }
    for (const n in outputs.settings) {
        ctx.settings[n] = outputs.settings[n];
    }
    if (!ctx.extras) {
        ctx.extras = {};
    }
    for (const n in outputs.extras) {
        ctx.extras[n] = outputs.extras[n];
    }
    for (const override in ctx.overrideSettings) {
        ctx.settings[override] = ctx.overrideSettings[override];
    }
    assignSettingsToExtras(ctx);
    ctx = Object.assign(ctx, addSimplifiedAccessSyntax(ctx));
}
exports.addOutputsToContext = addOutputsToContext;
// backawrds compatibility, settings was called "extras".
function assignSettingsToExtras(ctx) {
    if (ctx.settings) {
        ctx.extras = {
            ...(ctx.extras || {}),
            ...ctx.settings,
        };
    }
    for (const importCtx of Object.values(ctx.imports || {})) {
        assignSettingsToExtras(importCtx);
    }
}
//# sourceMappingURL=builder.js.map