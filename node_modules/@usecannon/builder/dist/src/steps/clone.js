"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const chalk_1 = require("chalk");
const debug_1 = __importDefault(require("debug"));
const lodash_1 = __importDefault(require("lodash"));
const access_recorder_1 = require("../access-recorder");
const builder_1 = require("../builder");
const constants_1 = require("../constants");
const definition_1 = require("../definition");
const package_1 = require("../package");
const runtime_1 = require("../runtime");
const schemas_1 = require("../schemas");
const package_json_1 = __importDefault(require("../../package.json"));
const debug = (0, debug_1.default)('cannon:builder:clone');
// ensure the specified contract is already deployed
// if not deployed, deploy the specified hardhat contract with specfied options, export address, abi, etc.
// if already deployed, reexport deployment options for usage downstream and exit with no changes
const cloneSpec = {
    label: 'clone',
    validate: schemas_1.cloneSchema,
    async getState() {
        // Always re-run the operation
        return [];
    },
    configInject(ctx, config, packageState) {
        config = lodash_1.default.cloneDeep(config);
        if (config.target && config.targetPreset) {
            throw new Error(`only one of \`target\` and \`targetPreset\` can specified for ${packageState.name}`);
        }
        const ref = new package_1.PackageReference(lodash_1.default.template(config.source)(ctx));
        config.source = ref.fullPackageRef;
        if (config.sourcePreset) {
            config.source = package_1.PackageReference.from(ref.name, ref.version, config.sourcePreset).fullPackageRef;
        }
        config.sourcePreset = lodash_1.default.template(config.sourcePreset)(ctx);
        config.targetPreset = lodash_1.default.template(config.targetPreset)(ctx) || `with-${packageState.name}`;
        config.target = lodash_1.default.template(config.target)(ctx);
        if (config.var) {
            config.var = lodash_1.default.mapValues(config.var, (v) => {
                return lodash_1.default.template(v)(ctx);
            });
        }
        else if (config.options) {
            config.options = lodash_1.default.mapValues(config.options, (v) => {
                return lodash_1.default.template(v)(ctx);
            });
        }
        if (config.tags) {
            config.tags = config.tags.map((t) => lodash_1.default.template(t)(ctx));
        }
        return config;
    },
    getInputs(config, possibleFields) {
        let accesses = (0, access_recorder_1.computeTemplateAccesses)(config.source);
        accesses = (0, access_recorder_1.mergeTemplateAccesses)(accesses, (0, access_recorder_1.computeTemplateAccesses)(config.target, possibleFields));
        accesses = (0, access_recorder_1.mergeTemplateAccesses)(accesses, (0, access_recorder_1.computeTemplateAccesses)(config.sourcePreset, possibleFields));
        accesses = (0, access_recorder_1.mergeTemplateAccesses)(accesses, (0, access_recorder_1.computeTemplateAccesses)(config.targetPreset, possibleFields));
        if (config.options) {
            lodash_1.default.forEach(config.options, (a) => (accesses = (0, access_recorder_1.mergeTemplateAccesses)(accesses, (0, access_recorder_1.computeTemplateAccesses)(a, possibleFields))));
        }
        if (config.tags) {
            lodash_1.default.forEach(config.tags, (a) => (accesses = (0, access_recorder_1.mergeTemplateAccesses)(accesses, (0, access_recorder_1.computeTemplateAccesses)(a, possibleFields))));
        }
        return accesses;
    },
    getOutputs(_, packageState) {
        return [`imports.${packageState.currentLabel.split('.')[1]}`, `${packageState.currentLabel.split('.')[1]}`];
    },
    async exec(runtime, ctx, config, packageState) {
        const importLabel = packageState.currentLabel.split('.')[1] || '';
        debug(`[clone.${importLabel}]`, 'exec', config);
        const targetPreset = config.targetPreset ?? 'main';
        const sourcePreset = config.sourcePreset;
        const sourceRef = new package_1.PackageReference(config.source);
        const source = sourceRef.fullPackageRef;
        const target = config.target || `${sourceRef.name}:${sourceRef.version}@${targetPreset}`;
        const targetRef = new package_1.PackageReference(target);
        const chainId = config.chainId ?? constants_1.CANNON_CHAIN_ID;
        // try to read the chain definition we are going to use
        const deployInfo = await runtime.readDeploy(source, chainId);
        if (!deployInfo) {
            throw new Error(`deployment not found: ${source}. please make sure it exists for preset ${sourcePreset || sourceRef.preset} and network ${chainId}.`);
        }
        const importPkgOptions = { ...(deployInfo?.options || {}), ...(config.var || config.options || {}) };
        debug(`[clone.${importLabel}]`, 'cloning package options', importPkgOptions);
        // prior to importing the name, ensure the target names/version fields are set on the definition
        deployInfo.def.name = targetRef.name;
        deployInfo.def.version = targetRef.version;
        deployInfo.def.preset = targetRef.preset;
        const def = new definition_1.ChainDefinition(deployInfo.def);
        // always treat upstream state as what is used if its available. otherwise, we might have a state from a previous upgrade.
        // if all else fails, we can load from scratch (aka this is first deployment)
        let prevState = {};
        let prevMiscUrl = null;
        // also do not restore previous state for any network that snapshots--its not possible to restore state snapshots, so we have to rebuild
        if (!runtime.snapshots && ctx.imports[importLabel]?.url) {
            const prevUrl = ctx.imports[importLabel].url;
            debug(`[clone.${importLabel}]`, `using state from previous deploy: ${prevUrl}`);
            const prevDeployInfo = await runtime.readBlob(prevUrl);
            prevState = prevDeployInfo.state;
            prevMiscUrl = prevDeployInfo.miscUrl;
        }
        else {
            // sanity: there shouldn't already be a build in our way
            // if there is, we need to overwrite it. print out a warning.
            if (await runtime.readDeploy(source, runtime.chainId)) {
                debug(`[clone.${importLabel}]`, (0, chalk_1.yellow)('There is a pre-existing deployment for this preset and chain id. This build will overwrite. Did you mean `import`?'));
            }
            debug(`[clone.${importLabel}]`, 'no previous state found, deploying from scratch');
        }
        // TODO: needs npm package from the manifest
        const initialCtx = await (0, builder_1.createInitialContext)(def, deployInfo.meta, runtime.chainId, importPkgOptions);
        // use separate runtime to ensure everything is clear
        // we override `getArtifact` to use a simple loader from the upstream misc data to ensure that any contract upgrades are captured as expected
        // but if any other misc changes are generated they will still be preserved through the new separate context misc
        const upstreamMisc = await runtime.readBlob(deployInfo.miscUrl);
        const importRuntime = runtime.derive({
            getArtifact: (n) => {
                return upstreamMisc.artifacts[n];
            },
        });
        let partialDeploy = false;
        importRuntime.on(runtime_1.Events.SkipDeploy, () => {
            partialDeploy = true;
        });
        // need to import the misc data for the imported package
        if (prevMiscUrl) {
            debug(`[clone.${importLabel}]`, 'load misc');
            await importRuntime.restoreMisc(prevMiscUrl);
        }
        debug(`[clone.${importLabel}]`, 'start build');
        const builtState = await (0, builder_1.build)(importRuntime, def, prevState, initialCtx);
        if (importRuntime.isCancelled()) {
            partialDeploy = true;
        }
        debug(`[clone.${importLabel}]`, 'finish build. is partial:', partialDeploy);
        if (!lodash_1.default.isEmpty(prevState) && lodash_1.default.isEqual(builtState, prevState)) {
            debug(`[clone.${importLabel}]`, 'built state is exactly equal to previous state. skip generation of new deploy url', importLabel);
            return {
                imports: {
                    [importLabel]: ctx.imports[importLabel],
                },
            };
        }
        const newMiscUrl = await importRuntime.recordMisc();
        debug(`[clone.${importLabel}]`, 'new misc:', newMiscUrl);
        // need to save state to IPFS now so we can access it in future builds
        const newSubDeployUrl = await runtime.putDeploy({
            // TODO: add cannon version number?
            generator: `cannon clone ${package_json_1.default.version}`,
            timestamp: Math.floor(Date.now() / 1000),
            def: def.toJson(),
            miscUrl: newMiscUrl || '',
            options: importPkgOptions,
            state: builtState,
            meta: deployInfo.meta,
            status: partialDeploy ? 'partial' : 'complete',
            chainId,
        });
        if (!newSubDeployUrl) {
            debug(`[clone.${importLabel}]`, 'warn: cannot record built state for import nested state');
        }
        else {
            await runtime.registry.publish([target, ...(config.tags || ['latest']).map((t) => config.source.split(':')[0] + ':' + t)], runtime.chainId, newSubDeployUrl, (await runtime.registry.getMetaUrl(source, chainId)) || '');
        }
        return {
            imports: {
                [importLabel]: {
                    url: newSubDeployUrl || '',
                    tags: config.tags || ['latest'],
                    target: targetRef.fullPackageRef,
                    preset: targetRef.preset,
                    ...(await (0, builder_1.getOutputs)(importRuntime, def, builtState)),
                },
            },
        };
    },
    timeout: 3600000,
};
exports.default = cloneSpec;
//# sourceMappingURL=clone.js.map